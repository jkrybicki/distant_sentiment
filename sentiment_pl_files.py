# -*- coding: utf-8 -*-
"""sentiment_pl_files.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bvekLb70LK8acwSVBCKPZt-X8VaDxpRt
"""

from google.colab import drive
drive.mount('/content/drive/')

import os, glob, re, nltk

os.chdir('/content/drive/MyDrive/Fourth Glance/corpus')

os.getcwd()

pip install sentimentpl sacremoses

from sentimentpl.models import SentimentPLModel

model = SentimentPLModel(from_pretrained='latest')

from nltk.tokenize import sent_tokenize

nltk.download('punkt')

import pandas as pd

df = pd.DataFrame(columns=['text', 'mean_sent'])

dict_list = []

for filename in glob.glob('kraszewski*.txt'):
  with open(os.path.join(os.getcwd(), filename), 'r') as f:
      lines = f.read()
      sentences = sent_tokenize(lines)
      result = []
      for sentence in sentences:
        if len(re. findall(r'\w+', sentence)) < 300:
          sentiment_file = model(sentence).item()
          result.append(sentiment_file)
      dupa = sum(tuple(result))/len(tuple(result))
  row_dict = {'text': filename, 'mean_sent': dupa}
  dict_list.append(row_dict)
  df = pd.DataFrame.from_dict(dict_list)
  df.to_csv('../sent_mean_latest.csv', mode='a')
  df = pd.DataFrame(columns=['text', 'mean_sent'])
  dict_list = []

#file1 = open("../sent_mean_latest.csv", "a")  # append mode
#file1.writelines(row_dict)
#file1.close()

#dict_list

#df = pd.DataFrame.from_dict(dict_list)

#df

#file1.to_csv('../sent_mean_latest.csv')